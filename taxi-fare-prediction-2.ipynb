{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecba548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f9d8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MEMORY = \"5g\"\n",
    "spark = SparkSession.builder.appName(\"taxi-duration-prediction-2\")\\\n",
    "            .config(\"spark.executor.memory\", MAX_MEMORY)\\\n",
    "            .config(\"spark.driver.memory\", MAX_MEMORY).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2745af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_files = \"/home/jovyan/trips/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "701bee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df = spark.read.csv(f\"file:///{trip_files}\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cb77c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      " |-- airport_fee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba52ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.createOrReplaceTempView(\"trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c365bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    CAST(passenger_count AS double),\n",
    "    PULocationID as pickup_location_id,\n",
    "    DOLocationID as dropoff_location_id,\n",
    "    CAST(trip_distance AS double),\n",
    "    HOUR(tpep_pickup_datetime) as pickup_time,\n",
    "    DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,\n",
    "    CAST(total_amount AS double)\n",
    "FROM\n",
    "    (SELECT\n",
    "        *,\n",
    "        TO_DATE(t.tpep_pickup_datetime) AS pickup_date\n",
    "    FROM\n",
    "        trips t)\n",
    "WHERE\n",
    "    total_amount < 5000\n",
    "    AND total_amount > 0\n",
    "    AND trip_distance > 0\n",
    "    AND trip_distance < 500\n",
    "    AND passenger_count < 4\n",
    "    AND pickup_date >= '2021-01-01'\n",
    "    AND pickup_date < '2021-04-01'\n",
    "\"\"\"\n",
    "data_df = spark.sql(query)\n",
    "data_df.createOrReplaceTempView(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60163021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- pickup_location_id: string (nullable = true)\n",
      " |-- dropoff_location_id: string (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4023245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------+\n",
      "|summary|   passenger_count|     trip_distance|       pickup_time|day_of_week|\n",
      "+-------+------------------+------------------+------------------+-----------+\n",
      "|  count|          13180789|          13180789|          13180789|   13180789|\n",
      "|   mean|1.2169496074931478|3.5256582189433003|14.207635976875132|       NULL|\n",
      "| stddev|0.5477227418517697| 4.174284300086649|  5.27160400823842|       NULL|\n",
      "|    min|               0.0|               1.0|                 0|     Friday|\n",
      "|    max|               3.0|             475.5|                23|  Wednesday|\n",
      "+-------+------------------+------------------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select([\"passenger_count\", \"trip_distance\", \"pickup_time\", \"day_of_week\"]).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8770a96-3659-4a9e-97cc-a85020f81d5c",
   "metadata": {},
   "source": [
    "### Train, Test 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e44e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10542976\n",
      "2637813\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=1)\n",
    "print(train_df.count())\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9eea2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df = train_df.sample(False, .1, seed=261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4264f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 기반 포멧 parquet로 저장.. 압축률이 좋고 disk io가 적다 컬럼별로 적절한 인코딩이 가능\n",
    "data_dir = \"/home/jovyan/data\"\n",
    "train_df.write.format(\"parquet\").save(f\"{data_dir}/train/\")\n",
    "test_df.write.format(\"parquet\").save(f\"{data_dir}/test/\")\n",
    "toy_df.write.format(\"parquet\").save(f\"{data_dir}/toy/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb563660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 읽어오기\n",
    "train_df = spark.read.parquet(f\"{data_dir}/train/\")\n",
    "test_df = spark.read.parquet(f\"{data_dir}/test/\")\n",
    "toy_df = spark.read.parquet(f\"{data_dir}/toy/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13a87656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- pickup_location_id: string (nullable = true)\n",
      " |-- dropoff_location_id: string (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_time: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd6a8b-3201-4a1c-9ec2-7af568e990e0",
   "metadata": {},
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89ce77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "# 카테고리 피쳐들\n",
    "cat_feats = [\n",
    "    \"pickup_location_id\",\n",
    "    \"dropoff_location_id\",\n",
    "    \"day_of_week\",\n",
    "    \"pickup_time\",\n",
    "]\n",
    "\n",
    "# 파이프라인 스테이지\n",
    "stages = []\n",
    "\n",
    "# 카테고리 피쳐 프리프로세싱\n",
    "for c in cat_feats:\n",
    "    # c -> c_idx\n",
    "    cat_indexer = StringIndexer(inputCol=c, outputCol = c + \"_idx\").setHandleInvalid(\"keep\")\n",
    "    # one hot encode \n",
    "    onehot_encoder = OneHotEncoder(inputCols=[cat_indexer.getOutputCol()], outputCols=[c + \"_onehot\"])\n",
    "    stages += [cat_indexer, onehot_encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51a1a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Normalization\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "# Numerical 피쳐\n",
    "num_feats = [\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\"\n",
    "]\n",
    "\n",
    "# vector assembler\n",
    "for n in num_feats:\n",
    "    num_assembler = VectorAssembler(inputCols=[n], outputCol=n+\"_vector\")\n",
    "    num_scaler = StandardScaler(inputCol=num_assembler.getOutputCol(), outputCol=n+\"_scaled\")\n",
    "    stages += [num_assembler, num_scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1ce8c7f-680f-4e2b-9f4f-1d6c25426c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_961e6163f71c,\n",
       " OneHotEncoder_3a600812d9a6,\n",
       " StringIndexer_168ae784ed5a,\n",
       " OneHotEncoder_f7c7abb4d309,\n",
       " StringIndexer_3db75fc0edee,\n",
       " OneHotEncoder_300724997c9f,\n",
       " StringIndexer_a2bb0d84dec8,\n",
       " OneHotEncoder_3bc0588093db,\n",
       " VectorAssembler_22f3cc35f25a,\n",
       " StandardScaler_113cb516db41,\n",
       " VectorAssembler_3966ef57e6dd,\n",
       " StandardScaler_832150718971]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages   # 카테고리 + numerical 피쳐별로 6세트가 생김."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a25b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical + Numeric features\n",
    "assembler_inputs = [c + \"_onehot\" for c in cat_feats] + [n + \"_scaled\" for n in num_feats]\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"feature_vector\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f12cdfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# add model into the stages\n",
    "transform_stages = stages\n",
    "\n",
    "# Construct pipeline using the set of stages defined\n",
    "pipeline =  Pipeline(stages=transform_stages)\n",
    "\n",
    "# Fit the transformer\n",
    "fitted_transformer = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f94e46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train data\n",
    "transformed_train_df = fitted_transformer.transform(train_df)\n",
    "# transformed_train_df = transformed_train_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00dd87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(maxIter=100, \n",
    "                         solver=\"normal\", \n",
    "                         labelCol=\"total_amount\",\n",
    "                         featuresCol=\"feature_vector\",\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69c51934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(transformed_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c457bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46aa3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test_df = fitted_transformer.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "327e1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(transformed_test_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "627c4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+------------------+\n",
      "|trip_distance|day_of_week|total_amount|        prediction|\n",
      "+-------------+-----------+------------+------------------+\n",
      "|         14.9|     Friday|       66.35| 68.64659764171763|\n",
      "|         16.2|   Thursday|       60.35| 70.75679896277349|\n",
      "|          2.4|   Thursday|        12.8|18.133372777694163|\n",
      "|          3.0|   Thursday|       18.75|19.597865666447444|\n",
      "|          1.0|   Thursday|        11.8|13.789339998675738|\n",
      "|          1.5|     Friday|       14.08|14.844348293357143|\n",
      "|          1.6|     Friday|       13.55|14.312911841429377|\n",
      "|          1.9|    Tuesday|        18.5|14.908396038896326|\n",
      "|          2.2|     Monday|        15.3|15.328428877262382|\n",
      "|          2.0|   Thursday|       17.15|  16.3342360650431|\n",
      "|          2.1|     Monday|        16.3| 17.44294965203698|\n",
      "|          2.7|   Saturday|        18.3| 18.79501683218274|\n",
      "|          4.3|     Monday|        20.8| 21.96263443893573|\n",
      "|          3.4|   Saturday|       22.85|18.831033569126383|\n",
      "|          9.6|     Monday|        32.3|35.878216320204686|\n",
      "|          4.2|     Monday|        19.3| 21.91983985829993|\n",
      "|          1.1|     Monday|        12.8|12.514014842329527|\n",
      "|          1.2|  Wednesday|       12.96| 13.74124751444552|\n",
      "|          2.0|     Monday|        16.8|13.878326392377524|\n",
      "|          2.3|    Tuesday|        13.8| 14.37091722954381|\n",
      "+-------------+-----------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select([\"trip_distance\", \"day_of_week\", \"total_amount\", \"prediction\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e55bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "distance_list = [1.1, 5.5, 10.5, 30.0]\n",
    "distances_df = spark.createDataFrame(distance_list, DoubleType()).toDF(\"trip_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc43781",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdistances_df = vassembler.transform(distances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vdistances_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transform(vdistances_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ccd89",
   "metadata": {},
   "source": [
    "# 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "859f2b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.regression.LinearRegressionTrainingSummary at 0xffff47808050>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ee6b0957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  6.119912904998628\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", model.summary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78e1580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.8069741997402999\n"
     ]
    }
   ],
   "source": [
    "print(\"R2: \", model.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01dc1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+------------------+-----------+------------------+\n",
      "|summary|   passenger_count|pickup_location_id|dropoff_location_id|     trip_distance|       pickup_time|day_of_week|      total_amount|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-----------+------------------+\n",
      "|  count|          10542976|          10542976|           10542976|          10542976|          10542976|   10542976|          10542976|\n",
      "|   mean|1.2169354269610402|164.29842295002854| 161.28775262316825| 3.526571795286053|14.207018018441852|       NULL|20.265381998326152|\n",
      "| stddev|0.5477710193637441| 65.58302058496625|   71.5275341911363|4.1746303495386075| 5.271293246375481|       NULL|13.929565868586424|\n",
      "|    min|               0.0|                 1|                  1|               1.0|                 0|     Friday|               1.0|\n",
      "|    max|               3.0|                99|                 99|             452.0|                23|  Wednesday|            4973.3|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc1254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
